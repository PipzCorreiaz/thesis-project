\subsection{Monte Carlo Tree Search}


\gls{mcts} is a family of algorithms, which goal is to find optimal decisions.
This method incrementally builds a search tree according to the results of previous iterations.
The search tree is expanded by randomly sampling the nodes.
Usually, it is divided into four steps, as described bellow.
\begin{itemize}
  \item Selection: Select a child node through a selection policy. This policy must balance between unexplored areas of the tree and promising nodes that may lead to higher rewards.
  \item Expansion: Expand the selected node to add one or more nodes to the tree, according to the available actions.
  \item Simulation: Select an expanded node through a simulation or default policy to produce an outcome.
  \item Backpropagation: Propagate the reward value of all the selected nodes in order to update their statistics.
\end{itemize}
\todo{Do I need to give more characteristics of mcts? Or strengths? Or weaknesses?}

According to Browne et al. in 2012, finding a suitable variation of \gls{mcts} is the greatest challenge of applying the algorithm to a specific environment.
The most popular algorithm of \gls{mcts} family is \gls{uct} algorithm.
The \gls{uct} variation differs from the original in the selection phase.
It uses a maximization function to evaluate the available nodes.
This function establishes an equilibrium between exploration and exploitation, through a given constant value.
A considerable amount of iterations will approximate the \gls{uct} to a minimax tree.
Consequently, the produced results are nearly optimal.

